# Knowledge Graph Pipeline - Documentation

> Documentation compl√®te du pipeline de construction du Knowledge Graph par agents IA

---

## Vue d'Ensemble

Le **KG Pipeline** est un syst√®me modulaire qui construit automatiquement un Knowledge Graph √† partir de documents structur√©s (CSV, JSON, etc.) en utilisant des agents IA (Claude via OpenRouter).

### Architecture

```
üìÑ Document (CSV, JSON, PDF, TXT)
    ‚Üì
üîç Parser (analyse format, extraction)
    ‚Üì
ü§ñ Agent Entity Extractor (Claude identifie entit√©s + propri√©t√©s)
    ‚Üì
üîó Agent Relation Extractor (Claude identifie relations)
    ‚Üì
üíæ Neo4j Storage (stockage nodes et edges)
    ‚Üì
‚úÖ Validation (statistiques, d√©duplication)
```

---

## Composants

### 1. Models (`backend/src/kg/models/`)

#### `entity.py` - Entit√©s (Nodes)

```python
class EntityType(str, Enum):
    PERSON = "Person"
    MOVIE = "Movie"
    STUDIO = "Studio"
    ORGANIZATION = "Organization"
    LOCATION = "Location"
    CONCEPT = "Concept"
    GENERIC = "Generic"

class Entity(BaseModel):
    type: EntityType
    name: str  # Identifiant unique
    properties: Dict[str, Any]  # Propri√©t√©s flexibles
    source: Optional[str]  # Document source
    confidence: float  # Score de confiance (0-1)
    neo4j_id: Optional[str]  # ID Neo4j apr√®s cr√©ation
```

**Exemples d'entit√©s:**
- Person: `{type: "Person", name: "Tom Hanks", properties: {birth_year: 1956, role: "actor"}}`
- Movie: `{type: "Movie", name: "Forrest Gump", properties: {year: 1994, genre: "Drama", rating: 8.8}}`
- Studio: `{type: "Studio", name: "Paramount Pictures", properties: {country: "USA"}}`

#### `relation.py` - Relations (Edges)

```python
class RelationType(str, Enum):
    ACTED_IN = "ACTED_IN"
    DIRECTED = "DIRECTED"
    PRODUCED_BY = "PRODUCED_BY"
    WORKS_AT = "WORKS_AT"
    KNOWS = "KNOWS"
    RELATED_TO = "RELATED_TO"

class Relation(BaseModel):
    type: RelationType
    from_entity: str  # Nom de l'entit√© source
    to_entity: str    # Nom de l'entit√© cible
    properties: Dict[str, Any]  # Props (role, budget, etc.)
    confidence: float
```

**Exemples de relations:**
- `Tom Hanks -[ACTED_IN {role: "Forrest"}]-> Forrest Gump`
- `Christopher Nolan -[DIRECTED]-> Inception`
- `The Dark Knight -[PRODUCED_BY {budget: 185M}]-> Warner Bros`

#### `document.py` - Tracking de traitement

```python
class ProcessingStatus(str, Enum):
    PENDING = "pending"
    PARSING = "parsing"
    EXTRACTING_ENTITIES = "extracting_entities"
    EXTRACTING_RELATIONS = "extracting_relations"
    STORING = "storing"
    VALIDATING = "validating"
    COMPLETED = "completed"
    FAILED = "failed"

class Document(BaseModel):
    filename: str
    format: DocumentFormat  # CSV, JSON, PDF, TXT
    status: ProcessingStatus
    progress: float  # 0-100%
    entities_extracted: int
    relations_extracted: int
    error: Optional[str]
```

---

### 2. Parsers (`backend/src/kg/parsers/`)

#### `csv_parser.py` - Parser CSV

**Fonctionnalit√©s:**
- Auto-d√©tection encoding (chardet)
- Auto-d√©tection d√©limiteur (`,`, `;`, `\t`, `|`)
- Inf√©rence de types de colonnes (int, float, date, boolean, string)
- G√©n√©ration de m√©tadonn√©es
- Statistiques par colonne

**Usage:**
```python
from src.kg.parsers.csv_parser import CSVParser

parser = CSVParser()
df, metadata = parser.parse(Path("data/movies.csv"))

# metadata contient:
# - filename, size_bytes, encoding, delimiter
# - row_count, column_count, columns
# - column_types, sample_rows
```

---

### 3. Agents (`backend/src/kg/agents/`)

#### `entity_extractor_agent.py` - Extraction d'entit√©s

**Fonctionnement:**
1. Re√ßoit les donn√©es CSV pars√©es
2. Construit un prompt structur√© pour Claude
3. Envoie √† OpenRouter (Claude 3.5 Sonnet)
4. Parse la r√©ponse JSON
5. Cr√©e des objets Entity
6. D√©duplique par (type, name)

**Prompt Claude:**
- Instructions claires sur types d'entit√©s √† extraire
- M√©tadonn√©es CSV (colonnes, types)
- Sample des donn√©es
- Format JSON strict
- Exemples

**Features:**
- Batch processing (50 records par appel)
- Temperature faible (0.1) pour coh√©rence
- Extraction multi-valeurs (acteurs s√©par√©s par `;`)
- Confidence scoring

#### `relation_extractor_agent.py` - Extraction de relations

**Fonctionnement:**
1. Re√ßoit les donn√©es CSV + entit√©s extraites
2. Construit prompt avec contexte des entit√©s
3. Claude identifie les relations
4. Valide que les entit√©s existent
5. Cr√©e des objets Relation
6. D√©duplique par (type, from, to)

**Validation:**
- V√©rifie que from_entity existe
- V√©rifie que to_entity existe
- Ignore les relations invalides

---

### 4. Services (`backend/src/kg/services/`)

#### `neo4j_service.py` - Interaction Neo4j

**Operations:**

**Entit√©s:**
```python
# Cr√©er une entit√©
entity_id = service.create_entity(entity)

# Cr√©er en batch
entity_ids = service.create_entities_batch(entities)

# Query
entity_data = service.get_entity_by_name("Tom Hanks")
```

**Relations:**
```python
# Cr√©er une relation
relation_id = service.create_relation(relation)

# Cr√©er en batch
relation_ids = service.create_relations_batch(relations)
```

**Statistiques:**
```python
stats = service.get_graph_stats()
# Retourne:
# - total_nodes, total_relationships
# - nodes_by_label (Person: 25, Movie: 10, ...)
# - relationships_by_type (ACTED_IN: 50, DIRECTED: 10, ...)
```

**Visualization:**
```python
graph_data = service.get_graph_data(limit=100)
# Retourne:
# - nodes: [{id, label, properties}, ...]
# - edges: [{id, from, to, type, properties}, ...]
```

**Cypher queries:**
- Utilise `MERGE` pour √©viter les duplicates
- `MATCH` par name pour cr√©er relations
- Transactions pour ACID compliance

#### `pipeline_orchestrator.py` - Orchestrateur

**Coordonne le pipeline complet:**

```python
orchestrator = get_orchestrator()
result = await orchestrator.process_file(
    file_path=Path("data/movies.csv"),
    file_format=DocumentFormat.CSV
)
```

**√âtapes:**
1. **Parse**: CSV ‚Üí DataFrame
2. **Extract Entities**: DataFrame ‚Üí List[Entity] (via Claude)
3. **Extract Relations**: DataFrame + Entities ‚Üí List[Relation] (via Claude)
4. **Store**: Entities + Relations ‚Üí Neo4j
5. **Validate**: Statistiques et v√©rifications

**Retourne:**
```json
{
  "status": "completed",
  "extraction": {
    "entities_extracted": 45,
    "relations_extracted": 78,
    "entities_by_type": {"Person": 25, "Movie": 10, "Studio": 10},
    "relations_by_type": {"ACTED_IN": 50, "DIRECTED": 10, ...}
  },
  "storage": {
    "entities_stored": 45,
    "relations_stored": 78
  },
  "graph_stats": {...}
}
```

---

### 5. API Routes (`backend/src/api/routes/kg.py`)

#### Endpoints disponibles:

**1. Upload document**
```http
POST /api/kg/upload
Content-Type: multipart/form-data

file: [fichier CSV/JSON/PDF/TXT]
```

**2. Process document**
```http
POST /api/kg/process/{filename}
```

**3. Upload + Process (combo)**
```http
POST /api/kg/upload-and-process
Content-Type: multipart/form-data

file: [fichier]
```

**4. Graph statistics**
```http
GET /api/kg/graph/stats
```

**5. Graph visualization**
```http
GET /api/kg/graph/visualization?limit=100
```

**6. Clear graph**
```http
DELETE /api/kg/graph/clear
‚ö†Ô∏è Supprime TOUTES les donn√©es !
```

**7. Health check**
```http
GET /api/kg/health
```

**8. List uploaded files**
```http
GET /api/kg/uploaded-files
```

---

## Usage

### 1. Via API (Curl)

```bash
# Upload et process
curl -X POST "http://localhost:8000/api/kg/upload-and-process" \
  -F "file=@data/movies.csv"

# Get stats
curl "http://localhost:8000/api/kg/graph/stats"

# Get visualization data
curl "http://localhost:8000/api/kg/graph/visualization?limit=50"
```

### 2. Via Python

```python
from pathlib import Path
from src.kg.services.pipeline_orchestrator import get_orchestrator
from src.kg.models.document import DocumentFormat

orchestrator = get_orchestrator()
result = await orchestrator.process_file(
    Path("data/movies.csv"),
    DocumentFormat.CSV
)
print(result)
```

### 3. Via Jupyter Notebook

```bash
# Lancer Jupyter
docker compose exec backend jupyter notebook \
  --ip=0.0.0.0 --port=8888 --no-browser --allow-root

# Ouvrir notebooks/06_kg_pipeline_test.ipynb
```

---

## Dataset de Test

### `data/test_datasets/movies_sample.csv`

10 films populaires avec:
- title, year, genre, rating
- director, studio, actors (multiples), budget

**Entit√©s extraites (~45):**
- 25+ Persons (acteurs + r√©alisateurs)
- 10 Movies
- 10 Studios

**Relations extraites (~78):**
- ACTED_IN (50+)
- DIRECTED (10)
- PRODUCED_BY (10)

---

## Tests

### Tests automatis√©s

```bash
# Run tests
docker compose exec backend pytest tests/kg/test_pipeline_e2e.py -v

# Tests inclus:
# - CSV parsing
# - Entity extraction
# - Relation extraction
# - Neo4j connection
# - Full pipeline end-to-end
```

### Tests manuels

**Jupyter Notebook:**
`backend/notebooks/06_kg_pipeline_test.ipynb`

Sections:
1. Parse CSV
2. Extract Entities
3. Extract Relations
4. Store in Neo4j
5. Graph Statistics
6. Test Complete Pipeline
7. Query Graph Data
8. Test Specific Entity
9. Cleanup

---

## Configuration

### Variables d'environnement

```bash
# OpenRouter (LLM)
OPENROUTER_API_KEY=your_key_here

# Neo4j
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=graphrag2024
```

### Settings

Dans `src/core/config.py`:
- `openrouter_api_key`: Cl√© API OpenRouter
- `neo4j_uri`, `neo4j_user`, `neo4j_password`: Connexion Neo4j

---

## Sch√©ma Initial: Movies & Actors

### Entit√©s

| Type | Propri√©t√©s | Exemple |
|------|-----------|---------|
| Person | name, role (actor/director), nationality | Tom Hanks |
| Movie | name, year, genre, rating, budget_millions | Forrest Gump (1994) |
| Studio | name, country, founded_year | Paramount Pictures |

### Relations

| Type | De | Vers | Propri√©t√©s | Exemple |
|------|-------|--------|-----------|---------|
| ACTED_IN | Person | Movie | role (character) | Tom Hanks -[ACTED_IN {role: "Forrest"}]-> Forrest Gump |
| DIRECTED | Person | Movie | - | Robert Zemeckis -[DIRECTED]-> Forrest Gump |
| PRODUCED_BY | Movie | Studio | budget_millions | Forrest Gump -[PRODUCED_BY {budget: 55}]-> Paramount |

---

## Extension Future

### Formats suppl√©mentaires
- JSON (structur√©)
- PDF (extraction texte + tables)
- TXT (non-structur√©)
- XLSX (Excel)

### Agents suppl√©mentaires
- **Validator Agent**: Coh√©rence, enrichissement, d√©duplication avanc√©e
- **Enrichment Agent**: Recherche d'informations compl√©mentaires
- **Resolution Agent**: Entity linking (Tom Hanks = Thomas J. Hanks)

### Features avanc√©es
- GraphRAG: Int√©gration dans l'agent vocal
- Temporal KG: √âvolution dans le temps
- Clustering: D√©tection de communaut√©s
- Inf√©rence: Relations implicites
- Multi-sources: APIs, scraping, bases de donn√©es

---

## Architecture Fichiers

```
backend/src/kg/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor_agent.py    # Agent extraction entit√©s
‚îÇ   ‚îî‚îÄ‚îÄ relation_extractor_agent.py  # Agent extraction relations
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ neo4j_service.py             # Service Neo4j
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_orchestrator.py     # Orchestrateur principal
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ entity.py                    # Model Entity
‚îÇ   ‚îú‚îÄ‚îÄ relation.py                  # Model Relation
‚îÇ   ‚îî‚îÄ‚îÄ document.py                  # Model Document
‚îî‚îÄ‚îÄ parsers/
    ‚îî‚îÄ‚îÄ csv_parser.py                # Parser CSV

backend/src/api/routes/
‚îî‚îÄ‚îÄ kg.py                            # API routes KG

backend/data/test_datasets/
‚îî‚îÄ‚îÄ movies_sample.csv                # Dataset de test

backend/tests/kg/
‚îî‚îÄ‚îÄ test_pipeline_e2e.py             # Tests end-to-end

backend/notebooks/
‚îî‚îÄ‚îÄ 06_kg_pipeline_test.ipynb        # Notebook de test
```

---

## Commandes Utiles

### D√©veloppement

```bash
# Lancer les services
make up

# Logs
make logs

# Backend shell
docker compose exec backend bash

# Python shell
docker compose exec backend python

# Jupyter
docker compose exec backend jupyter notebook \
  --ip=0.0.0.0 --port=8888 --no-browser --allow-root
```

### Neo4j

```bash
# Neo4j Browser
http://localhost:7474

# Cypher queries
MATCH (n) RETURN count(n)  # Count nodes
MATCH ()-[r]->() RETURN count(r)  # Count relationships
MATCH (n:Person) RETURN n LIMIT 10  # Get persons
MATCH (p:Person)-[r:ACTED_IN]->(m:Movie) RETURN p, r, m  # Get actors and movies
```

### API

```bash
# API Docs
http://localhost:8000/docs

# Test health
curl http://localhost:8000/api/kg/health
```

---

## D√©pendances Ajout√©es

```toml
# pyproject.toml
[tool.poetry.dependencies]
neo4j = "^5.15.0"         # Driver Neo4j
pandas = "^2.1.4"         # Parser CSV
chardet = "^5.2.0"        # D√©tection encoding
httpx = "^0.26.0"         # HTTP client (d√©j√† pr√©sent)
```

---

## Troubleshooting

### Erreur: "Neo4j connection failed"
- V√©rifier que Neo4j est lanc√©: `docker compose ps`
- V√©rifier les credentials dans `.env`
- Test connexion: `curl http://localhost:7474`

### Erreur: "OpenRouter API failed"
- V√©rifier `OPENROUTER_API_KEY` dans `.env`
- V√©rifier le quota/cr√©dit OpenRouter
- Test avec curl direct √† l'API

### Erreur: "CSV encoding detection failed"
- V√©rifier que chardet est install√©: `poetry show chardet`
- Tester avec encoding explicite: `parser.parse(file, encoding='utf-8')`

### Erreur: "Entity not found in extraction"
- Augmenter la temperature du LLM (actuellement 0.1)
- Am√©liorer le prompt avec plus d'exemples
- V√©rifier les donn√©es CSV (colonnes manquantes ?)

---

## Contact & Support

Pour questions ou probl√®mes:
1. V√©rifier cette documentation
2. Consulter les notebooks de test
3. V√©rifier les logs: `make logs`
4. Ouvrir une issue sur le repo

---

**Version:** 1.0.0
**Date:** 2026-01-07
**Branche:** KG
**Status:** ‚úÖ Op√©rationnel - Sprint 1 compl√©t√©
