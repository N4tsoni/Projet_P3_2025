# CLAUDE.md

Instructions pour Claude Code lors du travail sur ce projet.

---

## Vue d'Ensemble du Projet

**Jarvis** - Assistant vocal intelligent avec knowledge graph dynamique utilisant GraphRAG et Graphiti.

### Architecture

**Frontend:**
- Vue.js 3 + TypeScript + Vite
- Element Plus pour UI
- Atomic Design pattern
- Port: 5173

**Backend:**
- FastAPI + Python 3.11
- Whisper (STT local gratuit)
- Edge TTS (synthÃ¨se vocale gratuite)
- OpenRouter (LLM - Claude 3.5 Sonnet)
- Graphiti + Neo4j (knowledge graph)
- Port: 8000

**Infrastructure:**
- Docker + Docker Compose (3 services)
- Poetry pour dÃ©pendances Python
- Neo4j sur port 7474/7687

### Technologies ClÃ©s

- **STT**: Whisper Local (OpenAI open-source)
- **TTS**: Edge TTS Microsoft (voix fr-FR-DeniseNeural)
- **LLM**: OpenRouter (accÃ¨s Ã  100+ modÃ¨les)
- **Knowledge Graph**: Graphiti + Neo4j
- **Pipeline**: Audio â†’ Whisper â†’ Agent â†’ Edge TTS â†’ Audio

---

## Ã‰tat Actuel

### âœ… OpÃ©rationnel (Phases 1-3)

- Pipeline vocal complet fonctionnel
- Interface Vue.js moderne avec glassmorphism
- Enregistrement push-to-talk avec visualisation audio
- Historique des conversations
- API REST complÃ¨te
- Docker Compose avec 3 services
- Analyseur de code Python (nouveau dans `backend/src/code_analysis/`)

### ðŸ”„ En DÃ©veloppement (Phase 4)

- IntÃ©gration Graphiti pour mÃ©moire conversationnelle
- Extraction automatique d'entitÃ©s depuis transcriptions
- GraphRAG pour enrichissement contextuel

### ðŸ“¦ PlanifiÃ© (Phase 5+)

- Firmware ESP32 (matÃ©riel en commande)
- Wake word detection ("Hey Jarvis")
- Tests unitaires et d'intÃ©gration

---

## Structure du Projet

```
Projet_P3/
â”œâ”€â”€ frontend/          # Vue.js 3 + TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # Atomic Design
â”‚   â”‚   â”œâ”€â”€ stores/        # Pinia
â”‚   â”‚   â”œâ”€â”€ services/      # API client
â”‚   â”‚   â””â”€â”€ types/         # TypeScript
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ backend/           # FastAPI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/          # Routes REST
â”‚   â”‚   â”œâ”€â”€ agents/       # jarvis_agent.py
â”‚   â”‚   â”œâ”€â”€ voice/        # stt.py + tts.py
â”‚   â”‚   â”œâ”€â”€ code_analysis/  # Analyseur de code
â”‚   â”‚   â”œâ”€â”€ graph/        # Graphiti (en cours)
â”‚   â”‚   â””â”€â”€ models/       # Pydantic models
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ esp32/             # Firmware (Ã  dÃ©velopper)
â”œâ”€â”€ docs/              # Documentation
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â””â”€â”€ TODO.md           # Ã‰tat et prochaines Ã©tapes
```

---

## Commandes Essentielles

### DÃ©marrage
```bash
make build    # Build Docker images
make up       # Lancer tous les services
make down     # ArrÃªter
make logs     # Voir logs
```

### AccÃ¨s Services
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Neo4j: http://localhost:7474

### DÃ©veloppement
```bash
# Backend - Ajouter dÃ©pendance
docker-compose exec backend poetry add package-name

# Backend - Tests
docker-compose exec backend poetry run pytest

# Frontend
cd frontend && npm install && npm run dev
```

---

## Directives de DÃ©veloppement

### Principes

1. **ModularitÃ©**: Chaque composant (STT, TTS, Agent, Graph) est indÃ©pendant
2. **Async-first**: Utiliser async/await pour I/O
3. **Type safety**: TypeScript frontend, Pydantic backend
4. **Configuration centralisÃ©e**: `.env` pour backend
5. **Atomic Design**: Frontend organisÃ© en atoms â†’ molecules â†’ organisms â†’ templates

### Code Backend

- Utiliser **FastAPI** pour nouveaux endpoints
- **Pydantic** pour validation de donnÃ©es
- **Loguru** pour logging
- Services vocaux dans `src/voice/`
- Agent conversationnel dans `src/agents/`
- Code analysis dans `src/code_analysis/`

### Code Frontend

- **Vue 3 Composition API** + `<script setup>`
- **TypeScript** strict
- **Pinia** pour state management
- **Element Plus** pour composants UI
- Atomic Design dans `src/components/`

### Graphiti & Knowledge Graph

- Utiliser **Graphiti** pour knowledge graph dynamique
- **Neo4j** comme backend de graphe
- EntitÃ©s: Person, Event, Task, Note, Preference, Contact
- Relations: KNOWS, LIKES, SCHEDULED_FOR, RELATED_TO
- Code dans `backend/src/graph/`

---

## Workflow de DÃ©veloppement

### Ajout de FonctionnalitÃ©s

1. VÃ©rifier TODO.md pour contexte
2. DÃ©velopper de maniÃ¨re modulaire
3. Tester chaque composant
4. Mettre Ã  jour documentation si nÃ©cessaire

### Tests

- Tests unitaires avec pytest (backend)
- Tests d'intÃ©gration pour pipeline complet
- Validation manuelle via interface web

### Configuration

- `.env` backend: clÃ©s API, modÃ¨les, configurations
- Pas de secrets dans le code versioned
- `.env.example` comme template

---

## Points d'Attention

### Performance

- Whisper local peut Ãªtre lent (modÃ¨le "tiny" ou "base" recommandÃ©)
- Edge TTS rapide et gratuit
- Objectif latence totale: < 3s end-to-end

### SÃ©curitÃ©

- ClÃ©s API dans `.env` uniquement
- CORS configurÃ© pour dÃ©veloppement local
- Fichiers audio temporaires dans `backend/data/temp/` (ignorÃ©s par git)

### ESP32 (futur)

- MatÃ©riel en commande
- I2S pour microphone (INMP441) et speaker (MAX98357A)
- Wake word detection locale
- Communication WiFi avec backend

---

## Documentation

- **README.md**: Vue d'ensemble et dÃ©marrage rapide
- **TODO.md**: Ã‰tat actuel et prochaines Ã©tapes
- **ARCHITECTURE.md**: Architecture technique dÃ©taillÃ©e
- **START.md**: Guide ultra-rapide 30 secondes
- **docs/**: Documentation spÃ©cifique (QUICK_START, WEB_INTERFACE)

---

## Domaine: Assistant Personnel

Jarvis doit gÃ©rer:
- Informations personnelles (prÃ©fÃ©rences, contacts, habitudes)
- Ã‰vÃ©nements (rendez-vous, rappels, anniversaires)
- Connaissances mÃ©morisÃ©es depuis conversations
- TÃ¢ches et projets
- Contexte conversationnel
- Home automation (futur)

### Flow Conversationnel

1. **Capture**: Audio via microphone (web ou ESP32)
2. **STT**: Whisper transcrit en texte
3. **Agent**:
   - Recherche dans knowledge graph (GraphRAG)
   - GÃ©nÃ©ration rÃ©ponse via OpenRouter
   - Extraction nouvelles entitÃ©s Ã  mÃ©moriser
4. **Mise Ã  jour**: Graphiti stocke nouvelles informations
5. **TTS**: Edge TTS gÃ©nÃ¨re audio rÃ©ponse
6. **Lecture**: Audio renvoyÃ© Ã  l'utilisateur

---

## Ressources Utiles

- **Graphiti**: https://github.com/getzep/graphiti
- **OpenRouter**: https://openrouter.ai/docs
- **Whisper**: https://github.com/openai/whisper
- **Neo4j**: https://neo4j.com/docs/
- **ESP32 Audio**: https://github.com/atomic14/esp32_audio

---

## Notes Importantes

- Le projet utilise maintenant un frontend sÃ©parÃ© (Vue.js) au lieu de l'ancien `static/`
- `backend/src/code_analysis/` est un nouveau module pour analyser du code Python
- Les fichiers temporaires audio (.webm) dans `backend/data/temp/` ne doivent pas Ãªtre versionnÃ©s
- OpenRouter permet d'accÃ©der Ã  de nombreux modÃ¨les LLM (Claude, GPT-4, Llama, etc.)
